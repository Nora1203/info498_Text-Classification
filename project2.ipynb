{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70b28c0",
   "metadata": {},
   "source": [
    "## Train a logistic regression model for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3366e4c",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5aa6b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13248</td>\n",
       "      <td>569906532277731328</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Flight Attendant Complaints</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nic_tudobem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir She could even see that I had tri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 09:08:00 -0800</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13246</td>\n",
       "      <td>569906807696551936</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KaraAtDell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir those were snacks we left on purp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 09:09:05 -0800</td>\n",
       "      <td>Round Rock, TX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4748</td>\n",
       "      <td>569878685723049985</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SaraAMartens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir thanks for linking to #Passbook....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 07:17:21 -0800</td>\n",
       "      <td>Omaha, NE</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8249</td>\n",
       "      <td>568558887290441728</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>superhilarious</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue :/ he was trying to take stuff from t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 15:52:56 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5016</td>\n",
       "      <td>569538524321419265</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dirtytweetbacon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir last week I flew from DAL to LAX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 08:45:40 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            tweet_id airline_sentiment  \\\n",
       "0       13248  569906532277731328          negative   \n",
       "1       13246  569906807696551936          positive   \n",
       "2        4748  569878685723049985           neutral   \n",
       "3        8249  568558887290441728          negative   \n",
       "4        5016  569538524321419265          positive   \n",
       "\n",
       "   airline_sentiment_confidence               negativereason  \\\n",
       "0                        1.0000  Flight Attendant Complaints   \n",
       "1                        1.0000                          NaN   \n",
       "2                        0.6648                          NaN   \n",
       "3                        1.0000                   Bad Flight   \n",
       "4                        1.0000                          NaN   \n",
       "\n",
       "   negativereason_confidence    airline airline_sentiment_gold  \\\n",
       "0                     0.3855   American                    NaN   \n",
       "1                        NaN   American                    NaN   \n",
       "2                        NaN  Southwest                    NaN   \n",
       "3                     0.6990      Delta                    NaN   \n",
       "4                        NaN  Southwest                    NaN   \n",
       "\n",
       "              name negativereason_gold  retweet_count  \\\n",
       "0      nic_tudobem                 NaN              0   \n",
       "1       KaraAtDell                 NaN              0   \n",
       "2     SaraAMartens                 NaN              0   \n",
       "3   superhilarious                 NaN              0   \n",
       "4  dirtytweetbacon                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @AmericanAir She could even see that I had tri...         NaN   \n",
       "1  @AmericanAir those were snacks we left on purp...         NaN   \n",
       "2  @SouthwestAir thanks for linking to #Passbook....         NaN   \n",
       "3  @JetBlue :/ he was trying to take stuff from t...         NaN   \n",
       "4  @SouthwestAir last week I flew from DAL to LAX...         NaN   \n",
       "\n",
       "               tweet_created  tweet_location               user_timezone  \n",
       "0  2015-02-23 09:08:00 -0800        New York                         NaN  \n",
       "1  2015-02-23 09:09:05 -0800  Round Rock, TX                         NaN  \n",
       "2  2015-02-23 07:17:21 -0800       Omaha, NE  Central Time (US & Canada)  \n",
       "3  2015-02-19 15:52:56 -0800             NaN  Central Time (US & Canada)  \n",
       "4  2015-02-22 08:45:40 -0800             NaN                         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load twitter dataset into pandas and display\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('data/twitter_binary_classification_dataset/train.csv')\n",
    "df_test = pd.read_csv('data/twitter_binary_classification_dataset/test.csv')\n",
    "\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adf58444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  14640 tweets\n"
     ]
    }
   ],
   "source": [
    "# get tweet counts\n",
    "print(\"There are \", df_train['text'].count() + df_test['text'].count(), \"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e9e9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest tweet :  2015-02-16 23:36:05 -0800\n",
      "Lastest tweet in train data:  2015-02-24 11:53:37 -0800\n"
     ]
    }
   ],
   "source": [
    "# get earliest and latest tweet \n",
    "e_train = df_train['tweet_created'].min()\n",
    "l_train = df_train['tweet_created'].max()\n",
    "e_test = df_test['tweet_created'].min()\n",
    "l_test = df_test['tweet_created'].max()\n",
    "\n",
    "earliest = min(e_train, e_test)\n",
    "lastest = max(l_train, l_test)\n",
    "\n",
    "print(\"Earliest tweet : \", earliest)\n",
    "print(\"Lastest tweet in train data: \", lastest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac21b90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['American', 'Southwest', 'Delta', 'US Airways', 'United',\n",
       "       'Virgin America'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count unique airline\n",
    "df_train['airline'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3729a7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3822\n",
       "US Airways        2913\n",
       "American          2759\n",
       "Southwest         2420\n",
       "Delta             2222\n",
       "Virgin America     504\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get numbers of tweets per airline\n",
    "df_train['airline'].value_counts() + df_test['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be47b1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of tweets per sentiment label\n",
    "df_train['airline_sentiment'].value_counts() + df_test['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1afac0",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e0b8020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3125\n",
       "US Airways        2532\n",
       "American          2296\n",
       "Southwest         1756\n",
       "Delta             1499\n",
       "Virgin America     333\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with neutural sentiment label\n",
    "df_train = df_train.drop(df_train[df_train['airline_sentiment'] == 'neutral'].index)\n",
    "df_test = df_test.drop(df_test[df_test['airline_sentiment'] == 'neutral'].index)\n",
    "# get numbers of tweets per airline\n",
    "df_train['airline'].value_counts() + df_test['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c043709e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of tweets per sentiment label in binary dataset\n",
    "df_train['airline_sentiment'].value_counts() + df_test['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67335094",
   "metadata": {},
   "source": [
    "After removing all tweet that are neutral, there's no netural label in the binary dataset, while the number of positive and negative tweets doesn't change. The number of tweets for all the airlines dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728c2112",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "744cb90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@southwest',\n",
       " '@american',\n",
       " '@usairways',\n",
       " '@delta',\n",
       " '@united',\n",
       " '@virginamerica']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# get a list of lower cased and sapce removed airline names.\n",
    "air = []\n",
    "for i in df_test.airline.unique():\n",
    "    air.append(\"@\" + i.lower().replace(\" \", \"\"))\n",
    "air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a743acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the words that is same as words in air array in \"text\"\n",
    "for i in air:\n",
    "    df_test[\"text\"] = df_test.text.str.replace(i, \"\", case = False)\n",
    "\n",
    "for i in air:\n",
    "    df_train[\"text\"] = df_train.text.str.replace(i, \"\", case = False)\n",
    "\n",
    "# use TF-IDF vectorizer to convert texts into weighted vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit_transform learns the vocab and produces vectors at the same time\n",
    "train_vectors = vectorizer.fit_transform(df_train['text'])\n",
    "# transform uses the same vocab and produces vectors for the new data (test)\n",
    "test_vectors = vectorizer.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1e95d",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "929231ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['airline_sentiment'] = df_train['airline_sentiment'].map({'positive': 1, 'negative': 0})\n",
    "df_test['airline_sentiment'] = df_test['airline_sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ea221",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "942c9d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.9657273419649657\n",
      "Recall:0.6705446853516658\n",
      "F1-score: 0.7915106117353308\n",
      "Accuracy: 0.9276508177190512\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# create some dummy data\n",
    "X_train = train_vectors\n",
    "y_train = df_train['airline_sentiment']\n",
    "\n",
    "# train a LR classifier on train data\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict on train data\n",
    "yhat_train = lr.predict(X_train)\n",
    "\n",
    "# calculate performance on the train data\n",
    "precision = precision_score(y_train, yhat_train)\n",
    "f1score = f1_score(y_train, yhat_train)\n",
    "recall = recall_score(y_train, yhat_train)\n",
    "accuracy = accuracy_score(y_train, yhat_train)\n",
    "\n",
    "print(\"Precision:\" + str(precision))\n",
    "print(\"Recall:\" + str(recall))\n",
    "print(\"F1-score: \" + str(f1score))\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4e115",
   "metadata": {},
   "source": [
    "### Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "539f5bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.9352750809061489\n",
      "Recall:0.6122881355932204\n",
      "F1-score: 0.7400768245838668\n",
      "Accuracy: 0.9120450606585788\n"
     ]
    }
   ],
   "source": [
    "# create some dummy data\n",
    "X_test = test_vectors\n",
    "y_test = df_test['airline_sentiment']\n",
    "\n",
    "# predict on test data\n",
    "yhat_test = lr.predict(X_test)\n",
    "\n",
    "# calculate performance on the test data\n",
    "precision = precision_score(y_test, yhat_test)\n",
    "f1score = f1_score(y_test, yhat_test)\n",
    "recall = recall_score(y_test, yhat_test)\n",
    "accuracy = accuracy_score(y_test, yhat_test)\n",
    "\n",
    "print(\"Precision:\" + str(precision))\n",
    "print(\"Recall:\" + str(recall))\n",
    "print(\"F1-score: \" + str(f1score))\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca19f6c",
   "metadata": {},
   "source": [
    "From the result, we can see hat all the performance scores in testing data are lower than that of training data.The performance differences between the train and test splits suggest that the classifier is slightly overfitting to the training data. Overfitting occurs when a model learns the training data too well and doesn't generalize effectively to new, unseen data. This is why the performance metrics drop when applying the model to the test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd06d72",
   "metadata": {},
   "source": [
    "### Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "397e5839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix\n",
      "[[1816   20]\n",
      " [ 183  289]]\n"
     ]
    }
   ],
   "source": [
    "# show confusion matrix\n",
    "cm = confusion_matrix(y_test, yhat_test)\n",
    "print()\n",
    "print('Confusion matrix')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424e4b6f",
   "metadata": {},
   "source": [
    "True Positives (TP): 289 - the number of positive tweets correctly classified as positive.\n",
    "True Negatives (TN): 1816 - the number of negative tweets correctly classified as negative.\n",
    "False Positives (FP): 20 - the number of negative tweets incorrectly classified as positive.\n",
    "False Negatives (FN): 183 - the number of positive tweets incorrectly classified as negative.\n",
    "\n",
    "Class Imbalance: There's a class imbalance in the dataset, with more negative tweets (9178 tweets) than positive tweets (2363 tweets). This can lead to a model that is biased toward the majority class (negative sentiment). To mitigate this, techniques like resampling (oversampling the minority class), using vectir weights as what we done in question 3 would be useful.\n",
    "\n",
    "False Negatives: There are 183 FN, which are potentially problematic because they represent instances where positive sentiment was not recognized. To mitigate FN, fine-tune model hyperparameters, or use techniques like cost-sensitive learning to prioritize recall would be useful.\n",
    "\n",
    "False Positives: There are 20 FP. While this number is relatively low, it's still important to minimize FP, as misclassifying negative sentiment as positive could lead to incorrect insights. Work on improving the precision of the model could help reduce FN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66cc8d0",
   "metadata": {},
   "source": [
    "## Implement a KNN model for multi-class classification using BERT document embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d1cdf",
   "metadata": {},
   "source": [
    "### Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ffe50db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>Wall St. Bears Claw Back Into the Black (Reuters)</th>\n",
       "      <th>Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters)</td>\n",
       "      <td>Reuters - Stocks ended slightly higher on Frid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   3  Wall St. Bears Claw Back Into the Black (Reuters)  \\\n",
       "0  3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "1  3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "2  3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "3  3  Oil prices soar to all-time record, posing new...   \n",
       "4  3        Stocks End Up, But Near Year Lows (Reuters)   \n",
       "\n",
       "  Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.  \n",
       "0  Reuters - Private investment firm Carlyle Grou...                                              \n",
       "1  Reuters - Soaring crude prices plus worries\\ab...                                              \n",
       "2  Reuters - Authorities have halted oil export\\f...                                              \n",
       "3  AFP - Tearaway world oil prices, toppling reco...                                              \n",
       "4  Reuters - Stocks ended slightly higher on Frid...                                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_train = pd.read_csv('data/ag_news_multiclass_classification_dataset/train.csv')\n",
    "news_test = pd.read_csv('data/ag_news_multiclass_classification_dataset/test.csv')\n",
    "\n",
    "display(news_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b671636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  119999 news in the training split\n",
      "There are  7599 news in the testing split\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of news articles in each split\n",
    "print(\"There are \", len(news_train), \"news in the training split\")\n",
    "print(\"There are \", len(news_test), \"news in the testing split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "341587c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training document length: 236.47829565246377 characters\n",
      "Minimum training document length: 100 characters\n",
      "Maximum training document length: 1012 characters\n",
      "\n",
      "Average testing document length: 235.3089880247401 characters\n",
      "Minimum testing document length: 100 characters\n",
      "Maximum testing document length: 892 characters\n"
     ]
    }
   ],
   "source": [
    "# rename columns\n",
    "news_train.columns = [\"label\", \"title\", \"text\"]\n",
    "news_test.columns = [\"label\", \"title\", \"text\"]\n",
    "\n",
    "# concatenate title and text into a single news article\n",
    "news_train['document'] = news_train['title'] + ' ' + news_train['text']\n",
    "news_test['document'] = news_test['title'] + ' ' + news_test['text']\n",
    "\n",
    "# Calculate document lengths\n",
    "train_doc_lengths = news_train['document'].apply(len)\n",
    "test_doc_lengths = news_test['document'].apply(len)\n",
    "\n",
    "# Calculate summary statistics for document lengths\n",
    "train_avg_length = train_doc_lengths.mean()\n",
    "train_min_length = train_doc_lengths.min()\n",
    "train_max_length = train_doc_lengths.max()\n",
    "\n",
    "test_avg_length = test_doc_lengths.mean()\n",
    "test_min_length = test_doc_lengths.min()\n",
    "test_max_length = test_doc_lengths.max()\n",
    "\n",
    "print('Average training document length:', train_avg_length, 'characters')\n",
    "print('Minimum training document length:', train_min_length, 'characters')\n",
    "print('Maximum training document length:', train_max_length, 'characters')\n",
    "print()\n",
    "print('Average testing document length:', test_avg_length, 'characters')\n",
    "print('Minimum testing document length:', test_min_length, 'characters')\n",
    "print('Maximum testing document length:', test_max_length, 'characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e769382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4    30000\n",
       " 2    30000\n",
       " 1    30000\n",
       " 3    29999\n",
       " Name: label, dtype: int64,\n",
       " 4    1900\n",
       " 2    1900\n",
       " 1    1900\n",
       " 3    1899\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the distribution of labels in each split\n",
    "news_train['label'].value_counts(), news_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bbb604",
   "metadata": {},
   "source": [
    "The distribution of labels for both the train and test splits are nearly the same, each label has nearly the same counts within each split. This indicate the dataset is very balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2944c0",
   "metadata": {},
   "source": [
    "### Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80794693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 TF-IDF weighted tokens for label 3 : ['evansville', 'cox', 'axa', 'geico', 'giuliani', 'yo', 'anz', 'steel', 'accoona', 'sohu']\n",
      "Top 10 TF-IDF weighted tokens for label 4 : ['logger', 'dilithium', 'squip', 'blinkx', 'sulphur', 'gigaset', 'fpd', 'picasa', 'oddworld', 'sda']\n",
      "Top 10 TF-IDF weighted tokens for label 2 : ['lua', 'petke', 'trotter', 'maddox', 'bowl', 'numbers', 'distraction', 'brockton', 'quot', 'rostock']\n",
      "Top 10 TF-IDF weighted tokens for label 1 : ['azam', 'wrong', 'azzam', 'aceh', 'shipyard', 'lebanese', 'comprehensive', 'eritrea', 'nauru', 'anarchists']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(news_train.document)\n",
    "test_vectors = vectorizer.transform(news_test.document)\n",
    "\n",
    "# reference: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# get feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# find the highest tf-idf weighted tokens for each label\n",
    "for i in news_train.label.unique():\n",
    "    label_docs = train_vectors[news_train['label'] == i]\n",
    "    label_tfidf_max = label_docs.max(0).toarray()[0]\n",
    "    top_indices = label_tfidf_max.argsort()[-10:][::-1]\n",
    "    top_features = [feature_names[i] for i in top_indices]\n",
    "    print(\"Top 10 TF-IDF weighted tokens for label\", i, ':', top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4a336",
   "metadata": {},
   "source": [
    "Label 1: The top tokens in this category include terms like \"azam,\" \"aceh,\" \"eritrea,\" and \"anarchists\".  \"aceh\" might indicate a geographic location. This class may represent news related to global or regional events, possibly with a focus on conflict or social issues.\n",
    "\n",
    "Label 2: The top tokens in this category include terms like \"lua,\" \"trotter,\" \"bowl,\" and \"rostock.\" These terms may related to a variety of subjects but with a potential focus on sports.\n",
    "\n",
    "Label 3: The top tokens in this category include terms like \"evansville,\" \"cox,\" \"axa,\" \"geico,\" and \"giuliani.\" These terms seem to be related to names and companies. This class may represent news related to finance, insurance, and politics.\n",
    "\n",
    "Label 4: The top tokens in this category include terms like \"logger,\" \"dilithium,\" \"squip,\" and \"picasa.\" These terms appear to be more technical or related to software and technology.\n",
    "\n",
    "The actual labels are \"World\", \"Sports\", \"Business\", \"Sci/Tech\".  The guesses based on the top tokens appear to be quite accurate in identifying the general topic represented by each class label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd9077",
   "metadata": {},
   "source": [
    "### Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0d3f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thinkpad\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-F1: 0.90248716936439\n",
      "Macro-F1: 0.9021785029974404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# define dummys\n",
    "Xt = train_vectors\n",
    "yt = news_train.label\n",
    "Xv = test_vectors\n",
    "yv = news_test.label\n",
    "\n",
    "# create a KNN classifier with k=5 and cosine similarity\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='cosine')\n",
    "\n",
    "# train the KNN classifier on the training data\n",
    "knn.fit(Xt, yt)\n",
    "\n",
    "# predict labels for test data\n",
    "yv_hat = knn.predict(Xv)\n",
    "\n",
    "# calculate micro- and macro-F1 scores\n",
    "micro_f1 = f1_score(yv, yv_hat, average='micro')\n",
    "macro_f1 = f1_score(yv, yv_hat, average='macro')\n",
    "\n",
    "print(\"Micro-F1:\", micro_f1)\n",
    "print(\"Macro-F1:\", macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702266b",
   "metadata": {},
   "source": [
    "### Q12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40748eed",
   "metadata": {},
   "source": [
    "When comparing test documents against both train and test data, the risk of overfitting in the model's predictions increases. This is because the model may inadvertently incorporate characteristics of the test set into its decision-making process, leading to overly optimistic evaluations and poor generalization to new, unseen data.Spliting the training and testing dataset ensures a more accurate and unbiased assessment of the model's ability to classify new documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc503a",
   "metadata": {},
   "source": [
    "### Q13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73bb7e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.90      0.90      1900\n",
      "           2       0.94      0.97      0.96      1900\n",
      "           3       0.87      0.87      0.87      1899\n",
      "           4       0.89      0.87      0.88      1900\n",
      "\n",
      "    accuracy                           0.90      7599\n",
      "   macro avg       0.90      0.90      0.90      7599\n",
      "weighted avg       0.90      0.90      0.90      7599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "print(classification_report(yv, yv_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06d267c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: 4\n",
      "Predicted Label: 1\n",
      "The Shockwaves of Sumatra The Indian Ocean earthquake of December 2004 produced     a shockwave that created tsunamis all across the Indian Ocean. The tsunamis hammered nearby Indonesia and struck as far as     the coast of East Africa. The death toll has climbed over 100,000 and continues to grow.    It also created social shockwaves.  \n",
      "\n",
      "Actual Label: 2\n",
      "Predicted Label: 4\n",
      "Big Game Hunting Virginia, Navy and Maryland face season-defining games, perhaps &lt;em&gt;program-defining &lt;/em&gt;games for the Cavaliers and Midshipmen as they play against Florida State and Notre Dame, respectively on Saturday.\n",
      "\n",
      "Actual Label: 1\n",
      "Predicted Label: 3\n",
      "Vietnam Opens Bunker Used by Ho Chi Minh (AP) AP - Behind thick concrete walls and iron doors, Ho Chi Minh and other top Vietnamese leaders hid in secret underground tunnels during U.S. B-52 bombing raids to plot key military strategies that led to America's defeat in the Vietnam War.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# identify mis_classified documents\n",
    "mis_class = pd.DataFrame({\"document\": news_test.document, \"actual\": yv, \"predicted\": yv_hat})\n",
    "mis_class = mis_class[mis_class.actual != mis_class.predicted]\n",
    "sample_mis_class = mis_class.sample(3, random_state = 498)\n",
    "\n",
    "for index, row in sample_mis_class.iterrows():\n",
    "    print(\"Actual Label: \" + str(row.actual))\n",
    "    print(\"Predicted Label: \" + str(row.predicted))\n",
    "    print(row.document)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6ac54",
   "metadata": {},
   "source": [
    "1. Document 1: Actual Label - Sci/Tech, Predicted Label - World\n",
    "\n",
    "This document is primarily focuses on a natural disaster's social impacts. While the document contains scientific and technical elements related to earthquakes and tsunamis, it's more focused on the societal effects and geological terms. Given the emphasis on the earthquake's impact on human society, it's reasonable to categorize it as \"World\" rather than \"Sci/Tech.\"\n",
    "\n",
    "2. Document 2: Actual Label - Sports, Predicted Label - Sci/Tech\n",
    "\n",
    "This document mentions games involving several locations. The misclassification could be due to the mention of \"games\" and \"program-defining.\" However, it's more likely that these terms relate to sports rather than technology or science. This misclassification is less justified, and it would be more appropriate to categorize it as \"Sports.\"\n",
    "\n",
    "3. Document 3: Actual Label - World, Predicted Label - Business\n",
    "\n",
    "This document discusses a bunker used by Ho Chi Minh and other Vietnamese leaders during the Vietnam War. While there's a mention of B-52 bombing raids and military strategies, it primarily pertains to historical and political events. The misclassification as \"Business\" is less justifiable and likely due to a lack of clear context. The document is more appropriately categorized as \"World.\"\n",
    "\n",
    "In summary, document 2 and document 3 appears to have been truly misclassified, while document 1 is not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db49f0",
   "metadata": {},
   "source": [
    "### Q14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c243e4e",
   "metadata": {},
   "source": [
    "Logistic Regression is simple, efficient with large datasets, and interpretable. It's suitable for linear relationships but may not perform well with non-linear data. KNN is flexible, capturing non-linear patterns, but can be computationally expensive and sensitive to feature scaling. The choice between these two models depends on data and needs. Normally, ogistic Regression is good for interpretability and large datasets, while KNN suits complex non-linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01719c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
